{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"authorship_tag":"ABX9TyMbKGTK525va4gtoTXtzK31","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14374921,"sourceType":"datasetVersion","datasetId":9180167}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Probablistic retrival model, Fundamental of RAG","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:51.826862Z","iopub.execute_input":"2026-01-02T11:57:51.827636Z","iopub.status.idle":"2026-01-02T11:57:51.832186Z","shell.execute_reply.started":"2026-01-02T11:57:51.827595Z","shell.execute_reply":"2026-01-02T11:57:51.831284Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Initialize the tokenizer and the model\nmodel_id = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:51.862225Z","iopub.execute_input":"2026-01-02T11:57:51.862872Z","iopub.status.idle":"2026-01-02T11:57:53.271428Z","shell.execute_reply.started":"2026-01-02T11:57:51.862837Z","shell.execute_reply":"2026-01-02T11:57:53.270557Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model.transformer.wte.weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:53.272878Z","iopub.execute_input":"2026-01-02T11:57:53.273171Z","iopub.status.idle":"2026-01-02T11:57:53.281097Z","shell.execute_reply.started":"2026-01-02T11:57:53.273148Z","shell.execute_reply":"2026-01-02T11:57:53.280269Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Parameter containing:\ntensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n        ...,\n        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n       requires_grad=True)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(tokenizer.encode(\"<|endoftext|>\",return_tensors=\"pt\"))\nprint(tokenizer.decode(range(200)))\nprint(tokenizer.decode([20755]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:53.282115Z","iopub.execute_input":"2026-01-02T11:57:53.282516Z","iopub.status.idle":"2026-01-02T11:57:53.299267Z","shell.execute_reply.started":"2026-01-02T11:57:53.282485Z","shell.execute_reply":"2026-01-02T11:57:53.298527Z"}},"outputs":[{"name":"stdout","text":"tensor([[50256]])\n!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~����������������������������������������������������������������������������������������������\u0000\u0001\u0002\u0003\u0004\u0005\u0006\t\n\u000b\n impacted\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print(tokenizer)\nprint(f\"model:{model}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:53.300926Z","iopub.execute_input":"2026-01-02T11:57:53.301351Z","iopub.status.idle":"2026-01-02T11:57:53.312972Z","shell.execute_reply.started":"2026-01-02T11:57:53.301329Z","shell.execute_reply":"2026-01-02T11:57:53.312199Z"}},"outputs":[{"name":"stdout","text":"GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}\n)\nmodel:GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# simplified text generation function\nprompt = \"Dear boss ...\"\n\ndef simple_text_generation(prompt,model,tokenizer,max_length=100):\n    input_ids =  tokenizer.encode(prompt,return_tensors=\"pt\") # pt = pytorch\n    # print(f\"prompt:{prompt}\\n input_ids: {input_ids}\")\n    outputs = model.generate(input_ids,max_length=100)\n    \n    # print(f\"generated result: {outputs}\")\n    \n    sentence = tokenizer.decode(outputs[0],skip_special_tokens=True)\n    # print(f\"outputs: {sentence}\")\n    return sentence\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:53.314022Z","iopub.execute_input":"2026-01-02T11:57:53.314293Z","iopub.status.idle":"2026-01-02T11:57:53.326838Z","shell.execute_reply.started":"2026-01-02T11:57:53.314260Z","shell.execute_reply":"2026-01-02T11:57:53.325859Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"prompt = \"Dear boss ...\"\ntext_generated = simple_text_generation(prompt,\n                                        model,\n                                        tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:53.327814Z","iopub.execute_input":"2026-01-02T11:57:53.328080Z","iopub.status.idle":"2026-01-02T11:57:56.820868Z","shell.execute_reply.started":"2026-01-02T11:57:53.328051Z","shell.execute_reply":"2026-01-02T11:57:56.819919Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(text_generated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.821874Z","iopub.execute_input":"2026-01-02T11:57:56.822152Z","iopub.status.idle":"2026-01-02T11:57:56.826405Z","shell.execute_reply.started":"2026-01-02T11:57:56.822124Z","shell.execute_reply":"2026-01-02T11:57:56.825432Z"}},"outputs":[{"name":"stdout","text":"Dear boss ... I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.827251Z","iopub.execute_input":"2026-01-02T11:57:56.827565Z","iopub.status.idle":"2026-01-02T11:57:56.840105Z","shell.execute_reply.started":"2026-01-02T11:57:56.827533Z","shell.execute_reply":"2026-01-02T11:57:56.839290Z"}},"outputs":[{"name":"stdout","text":"GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}\n)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"data = sentences = [\n    \"this is all about tokenization\",\n    \"Tokenization transforms raw text into structured units called tokens, enabling language models to process sentences numerically while preserving linguistic meaning through consistent mapping between text fragments and integer identifiers.\",\n\n    \"Embedding layers convert token identifiers into dense continuous vectors, allowing neural networks to learn semantic similarity by placing related words closer together in high dimensional vector space during training.\",\n\n    \"Subword tokenization techniques such as byte pair encoding help models represent rare or unseen words by decomposing them into smaller meaningful units that still receive informative embeddings.\",\n\n    \"A tokenizer defines vocabulary size and token boundaries, directly influencing memory usage, sequence length, and the quality of embeddings learned by transformer based language models.\",\n\n    \"Word embeddings are learned parameters that capture semantic relationships, enabling models to infer meaning, analogy, and contextual relevance rather than treating words as isolated symbols.\",\n\n    \"When text is tokenized, punctuation, whitespace, and special characters are handled explicitly so the resulting token stream remains consistent across different inputs and training environments.\",\n\n    \"Embedding vectors are typically initialized randomly and gradually optimized through gradient descent so that contextual patterns in language are reflected in their numerical representations.\",\n\n    \"Tokenization choices affect downstream performance because poorly designed token splits can fragment meaning and make it harder for embedding layers to capture semantic coherence.\",\n\n    \"In transformer models, each token embedding represents a combination of lexical meaning and learned structure before positional information is added to encode word order.\",\n\n    \"Context independent embeddings assign one vector per token, while contextual embeddings adjust representations dynamically based on surrounding tokens within a sentence.\",\n\n    \"Padding tokens are introduced during tokenization to align sequence lengths in a batch, and their embeddings are usually masked to avoid influencing model predictions.\",\n\n    \"Embedding dimensions control the expressive power of a model, with larger dimensions allowing richer representations at the cost of increased computation and memory usage.\",\n\n    \"Tokenizers map text to integers deterministically, ensuring reproducibility so the same input sentence always produces identical token sequences across experiments.\",\n\n    \"Shared embedding spaces enable models to compare tokens mathematically, allowing cosine similarity or dot product operations to reveal semantic closeness between words.\",\n\n    \"Special tokens such as start of sequence and end of sequence guide models during training by clearly marking sentence boundaries in the tokenized input.\",\n\n    \"Tokenization errors propagate forward, meaning poorly segmented text can limit the quality of embeddings no matter how powerful the downstream neural architecture is.\",\n\n    \"Embedding layers act as a lookup table where each row corresponds to a token vector that is continuously refined as the model learns from large text datasets.\",\n\n    \"Character level tokenization avoids unknown words but increases sequence length dramatically, making embedding learning more computationally expensive for long inputs.\",\n\n    \"Subword embeddings strike a balance between vocabulary size and semantic granularity, making them effective for multilingual and low resource language modeling tasks.\",\n\n    \"During inference, tokenized text is passed through frozen embedding layers that transform symbolic input into numerical form suitable for matrix operations.\",\n\n    \"Embedding similarity allows models to generalize, so words appearing in similar contexts produce related vectors even if they never appear together explicitly.\",\n\n    \"Tokenization schemes differ across models, meaning embeddings trained with one tokenizer are generally incompatible with models expecting another vocabulary.\",\n\n    \"Learned embeddings encode both syntactic and semantic information, allowing models to understand grammatical roles as well as conceptual meaning.\",\n\n    \"Byte level tokenization ensures every possible input can be represented, but often produces longer token sequences requiring careful embedding optimization.\",\n\n    \"Embedding matrices can be inspected directly in frameworks like PyTorch, revealing how tokens correspond to rows of trainable numerical parameters.\",\n\n    \"Tokenization converts unstructured text into a discrete representation that neural networks can efficiently batch, embed, and process in parallel.\",\n\n    \"Pretrained embeddings provide a strong initialization that helps models converge faster by starting from linguistically informed representations.\",\n\n    \"Token embeddings are shared across all occurrences of a token, allowing consistent meaning to be reinforced across many training examples.\",\n\n    \"Positional embeddings are added to token embeddings so models can distinguish between identical tokens appearing at different positions in a sequence.\",\n\n    \"The quality of embeddings depends heavily on data diversity, since richer corpora expose tokens to varied contexts that shape their vector representations.\",\n\n    \"Tokenization must balance linguistic accuracy with computational efficiency to avoid unnecessary fragmentation of common words.\",\n\n    \"Embedding vectors live in continuous space, enabling smooth interpolation between meanings rather than rigid categorical distinctions.\",\n\n    \"Tokenizers handle casing rules differently, meaning lowercasing text can significantly impact embedding reuse and vocabulary size.\",\n\n    \"In causal language models, token embeddings are optimized to predict the next token, reinforcing contextual relationships through training objectives.\",\n\n    \"Embedding lookup is one of the first operations in a language model forward pass, transforming integer inputs into floating point tensors.\",\n\n    \"Subword tokenization helps reduce out of vocabulary issues while allowing embeddings to capture meaningful morphological patterns.\",\n\n    \"Embedding layers are typically followed by attention mechanisms that refine token representations based on interactions with neighboring tokens.\",\n\n    \"Tokenization defines how text is segmented, but embeddings determine how those segments are understood numerically by the model.\",\n\n    \"Training embeddings jointly with the model allows them to adapt to task specific language usage rather than remaining static.\",\n\n    \"Token embeddings encode prior knowledge learned during pretraining, enabling downstream tasks to benefit from general language understanding.\",\n\n    \"Whitespace handling during tokenization affects how embeddings represent word boundaries and sentence structure.\",\n\n    \"Embedding normalization techniques can improve stability by keeping vector magnitudes within reasonable bounds.\",\n\n    \"Tokenizers must be deterministic so embedding lookup remains consistent across distributed training environments.\",\n\n    \"Embedding similarity can reveal biases present in training data, as tokens reflecting similar contexts cluster together.\",\n\n    \"Special tokens receive their own embeddings, allowing models to treat structural markers differently from regular text tokens.\",\n\n    \"Tokenization errors often appear subtle but can degrade embedding quality in long sequences.\",\n\n    \"Embedding matrices grow linearly with vocabulary size, making efficient tokenization essential for scaling large models.\",\n\n    \"Contextual embeddings evolve across transformer layers, refining token meaning as more context is incorporated.\",\n\n    \"Tokenization is language dependent, so multilingual models rely heavily on shared subword embeddings.\",\n\n    \"Embedding layers are differentiable components that learn through gradient updates during backpropagation.\",\n\n    \"Token frequency influences embedding quality, as rare tokens receive fewer updates during training.\",\n\n    \"Embedding inspection helps researchers understand how models internalize linguistic structure.\",\n\n    \"Tokenizers define how numbers, symbols, and punctuation are represented before embedding lookup.\",\n\n    \"Embedding vectors allow models to compute relationships using linear algebra rather than symbolic rules.\",\n\n    \"Tokenization choices influence sequence length, which directly impacts attention complexity.\",\n\n    \"Embedding layers compress discrete token identities into dense numerical forms suitable for neural computation.\",\n\n    \"Poor tokenization can increase sequence length unnecessarily, reducing embedding efficiency.\",\n\n    \"Embedding sharing between input and output layers reduces parameters and improves generalization.\",\n\n    \"Tokenization determines the granularity at which meaning is represented in embeddings.\",\n\n    \"Embedding spaces often capture analogical relationships such as semantic similarity or oppositeness.\",\n\n    \"Tokenization pipelines must remain consistent between training and inference to preserve embedding alignment.\",\n\n    \"Embedding learning benefits from large corpora where tokens appear in diverse linguistic contexts.\",\n\n    \"Tokenizers may split words differently depending on prefixes, suffixes, or frequency statistics.\",\n\n    \"Embedding vectors are updated incrementally as models learn from prediction errors.\",\n\n    \"Tokenization is a preprocessing step, but embeddings are learned representations within the model.\",\n\n    \"Embedding dimensionality reflects a tradeoff between expressiveness and computational cost.\",\n\n    \"Tokenization errors are difficult to correct after embedding lookup has occurred.\",\n\n    \"Embedding layers serve as the bridge between symbolic language and numerical computation.\",\n\n    \"Tokenizers encode language rules implicitly through their vocabulary construction process.\",\n\n    \"Embedding similarity metrics enable semantic search and clustering applications.\",\n\n    \"Tokenization defines model input structure, while embeddings define representational meaning.\",\n\n    \"Embedding matrices can be visualized to analyze semantic clustering of tokens.\",\n\n    \"Tokenization must handle edge cases like emojis, URLs, and code snippets consistently.\",\n\n    \"Embedding vectors evolve during training to reflect task specific linguistic patterns.\",\n\n    \"Tokenization consistency ensures embeddings remain meaningful across different datasets.\",\n\n    \"Embedding layers translate discrete token indices into continuous feature representations.\",\n\n    \"Tokenization granularity affects how efficiently embeddings encode meaning.\",\n\n    \"Embedding quality is tightly coupled with tokenizer design decisions.\",\n\n    \"Tokenization strategies influence how models generalize to unseen text.\",\n\n    \"Embedding learning enables neural models to capture language structure without explicit rules.\",\n\n    \"Tokenization converts language into a format embeddings can transform into meaning.\",\n\n    \"Embedding layers are foundational components underlying modern natural language processing systems.\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.841901Z","iopub.execute_input":"2026-01-02T11:57:56.842174Z","iopub.status.idle":"2026-01-02T11:57:56.854280Z","shell.execute_reply.started":"2026-01-02T11:57:56.842152Z","shell.execute_reply":"2026-01-02T11:57:56.853432Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# all inputs must have the same length\n# add a dummy token at the end\n# Having the same length => this is called padding\n\ntokenizer.pad_token = tokenizer.eos_token \n\ntokenized_data = [tokenizer.encode_plus(\n    sentence,\n    add_special_tokens= True,\n    return_tensors=\"pt\",\n    padding=\"max_length\",\n    max_length=50,\n    \n) for sentence in data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.857676Z","iopub.execute_input":"2026-01-02T11:57:56.857952Z","iopub.status.idle":"2026-01-02T11:57:56.892337Z","shell.execute_reply.started":"2026-01-02T11:57:56.857931Z","shell.execute_reply":"2026-01-02T11:57:56.891564Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"tokenized_data[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.893169Z","iopub.execute_input":"2026-01-02T11:57:56.893456Z","iopub.status.idle":"2026-01-02T11:57:56.901944Z","shell.execute_reply.started":"2026-01-02T11:57:56.893426Z","shell.execute_reply":"2026-01-02T11:57:56.901265Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'input_ids': tensor([[ 5661,   318,   477,   546, 11241,  1634, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]])},\n {'input_ids': tensor([[30642,  1634, 31408,  8246,  2420,   656, 20793,  4991,  1444, 16326,\n             11, 15882,  3303,  4981,   284,  1429, 13439,  5470,  1146,   981,\n          23934, 29929,  3616,   832,  6414, 16855,  1022,  2420, 21441,   290,\n          18253, 42814,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]])}]"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"input_ids = [item[\"input_ids\"].squeeze() for item in tokenized_data]\nattention_masks = [mask[\"attention_mask\"].squeeze() for mask in tokenized_data]\ninput_ids[:5],attention_masks[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.902848Z","iopub.execute_input":"2026-01-02T11:57:56.903108Z","iopub.status.idle":"2026-01-02T11:57:56.920601Z","shell.execute_reply.started":"2026-01-02T11:57:56.903080Z","shell.execute_reply":"2026-01-02T11:57:56.919840Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"([tensor([ 5661,   318,   477,   546, 11241,  1634, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n  tensor([30642,  1634, 31408,  8246,  2420,   656, 20793,  4991,  1444, 16326,\n             11, 15882,  3303,  4981,   284,  1429, 13439,  5470,  1146,   981,\n          23934, 29929,  3616,   832,  6414, 16855,  1022,  2420, 21441,   290,\n          18253, 42814,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n  tensor([31567,  6048,   278, 11685, 10385, 11241, 42814,   656, 15715, 12948,\n          30104,    11,  5086, 17019,  7686,   284,  2193, 37865, 26789,   416,\n          12560,  3519,  2456,  5699,  1978,   287,  1029, 38517, 15879,  2272,\n           1141,  3047,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n  tensor([ 7004,  4775, 11241,  1634,  7605,   884,   355, 18022,  5166, 21004,\n           1037,  4981,  2380,  4071,   393, 29587,  2456,   416, 26969, 32927,\n            606,   656,  4833, 11570,  4991,   326,   991,  3328, 30304, 11525,\n             67,   654,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n  tensor([   32, 11241,  7509, 15738, 25818,  2546,   290, 11241, 13215,    11,\n           3264, 32596,  4088,  8748,    11,  8379,  4129,    11,   290,   262,\n           3081,   286, 11525,    67,   654,  4499,   416, 47385,  1912,  3303,\n           4981,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])],\n [tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]),\n  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]),\n  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]),\n  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]),\n  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0])])"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"### Convert the input_ids and attention mask to tensors","metadata":{}},{"cell_type":"code","source":"inputs_ids_tensor = torch.stack(input_ids)\nattention_masks_tensor = torch.stack(attention_masks)\ninputs_ids_tensor[:3],attention_masks_tensor[:3]\n\nprint(inputs_ids_tensor.shape)\n# print(input_ids.shape) # python list doesn't have shape property, that is why we change to torch tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.921753Z","iopub.execute_input":"2026-01-02T11:57:56.922125Z","iopub.status.idle":"2026-01-02T11:57:56.927070Z","shell.execute_reply.started":"2026-01-02T11:57:56.922101Z","shell.execute_reply":"2026-01-02T11:57:56.926256Z"}},"outputs":[{"name":"stdout","text":"torch.Size([83, 50])\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"padded_input_ids = pad_sequence(inputs_ids_tensor,\n             batch_first=True,\n             padding_value=tokenizer.eos_token_id)\npadded_attention_masks = pad_sequence(attention_masks_tensor,\n                                     batch_first=True,\n                                     padding_value=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.928048Z","iopub.execute_input":"2026-01-02T11:57:56.928424Z","iopub.status.idle":"2026-01-02T11:57:56.940776Z","shell.execute_reply.started":"2026-01-02T11:57:56.928345Z","shell.execute_reply":"2026-01-02T11:57:56.939933Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"padded_input_ids[:2],padded_attention_masks[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.941662Z","iopub.execute_input":"2026-01-02T11:57:56.942013Z","iopub.status.idle":"2026-01-02T11:57:56.960779Z","shell.execute_reply.started":"2026-01-02T11:57:56.941944Z","shell.execute_reply":"2026-01-02T11:57:56.960057Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 5661,   318,   477,   546, 11241,  1634, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n         [30642,  1634, 31408,  8246,  2420,   656, 20793,  4991,  1444, 16326,\n             11, 15882,  3303,  4981,   284,  1429, 13439,  5470,  1146,   981,\n          23934, 29929,  3616,   832,  6414, 16855,  1022,  2420, 21441,   290,\n          18253, 42814,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]),\n tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]]))"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self,input_ids,attention_masks):\n        self.input_ids = input_ids\n        self.attention_masks = attention_masks\n        self.labels = input_ids.clone()\n    def __len__(self):\n        return len(self.input_ids)\n    def __getitem__(self,index):\n        return {\n            \"input_ids\":self.input_ids[index],\n            \"attention_mask\":self.attention_masks[index],\n            \"labels\":self.labels[index]\n        }\n\n\ndataset = TextDataset(inputs_ids_tensor,attention_masks_tensor)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.961757Z","iopub.execute_input":"2026-01-02T11:57:56.962038Z","iopub.status.idle":"2026-01-02T11:57:56.974010Z","shell.execute_reply.started":"2026-01-02T11:57:56.962010Z","shell.execute_reply":"2026-01-02T11:57:56.973276Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"len(dataset),dataset[2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.974994Z","iopub.execute_input":"2026-01-02T11:57:56.975306Z","iopub.status.idle":"2026-01-02T11:57:56.989758Z","shell.execute_reply.started":"2026-01-02T11:57:56.975274Z","shell.execute_reply":"2026-01-02T11:57:56.988901Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(83,\n {'input_ids': tensor([31567,  6048,   278, 11685, 10385, 11241, 42814,   656, 15715, 12948,\n          30104,    11,  5086, 17019,  7686,   284,  2193, 37865, 26789,   416,\n          12560,  3519,  2456,  5699,  1978,   287,  1029, 38517, 15879,  2272,\n           1141,  3047,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0]),\n  'labels': tensor([31567,  6048,   278, 11685, 10385, 11241, 42814,   656, 15715, 12948,\n          30104,    11,  5086, 17019,  7686,   284,  2193, 37865, 26789,   416,\n          12560,  3519,  2456,  5699,  1978,   287,  1029, 38517, 15879,  2272,\n           1141,  3047,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n          50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])})"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"### Fine tuning the GPT2 model\n","metadata":{}},{"cell_type":"code","source":"data_loader = DataLoader(dataset,batch_size=2,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:56.990660Z","iopub.execute_input":"2026-01-02T11:57:56.990976Z","iopub.status.idle":"2026-01-02T11:57:57.004130Z","shell.execute_reply.started":"2026-01-02T11:57:56.990949Z","shell.execute_reply":"2026-01-02T11:57:57.003358Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# data_loader\n# for batch in data_loader:\n#     print(batch)\n#     print(\"\\n\"*5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:57.005012Z","iopub.execute_input":"2026-01-02T11:57:57.005373Z","iopub.status.idle":"2026-01-02T11:57:57.015843Z","shell.execute_reply.started":"2026-01-02T11:57:57.005351Z","shell.execute_reply":"2026-01-02T11:57:57.015002Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"model.parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:57.016661Z","iopub.execute_input":"2026-01-02T11:57:57.017293Z","iopub.status.idle":"2026-01-02T11:57:57.030259Z","shell.execute_reply.started":"2026-01-02T11:57:57.017262Z","shell.execute_reply":"2026-01-02T11:57:57.029463Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<bound method Module.parameters of GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(),lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:57.031292Z","iopub.execute_input":"2026-01-02T11:57:57.031671Z","iopub.status.idle":"2026-01-02T11:57:57.042385Z","shell.execute_reply.started":"2026-01-02T11:57:57.031641Z","shell.execute_reply":"2026-01-02T11:57:57.041534Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Set the model to training mode\nmodel.train()\n\n# Training loop\nfor epoch in range(10):\n    for batch in data_loader:\n        # Unpacking the input and atttention mask ids\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        # Reset the gradients to zero\n        optimizer.zero_grad() \n        #forward pass\n        outputs = model(input_ids=input_ids,\n                       attention_mask=attention_mask,\n                       labels=input_ids)\n        loss = outputs.loss\n        #backward pass\n        loss.backward()\n        #update the model parameters\n        optimizer.step()\n    # print the loss for the current epoch to monitor the progress\n    print(f\"Epoch {epoch+1} -Loss: {loss.item()}\")\n    \n        \n\n        \n\n\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:57:57.043305Z","iopub.execute_input":"2026-01-02T11:57:57.043495Z","iopub.status.idle":"2026-01-02T12:07:48.558161Z","shell.execute_reply.started":"2026-01-02T11:57:57.043477Z","shell.execute_reply":"2026-01-02T12:07:48.557199Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 -Loss: 1.1688239574432373\nEpoch 2 -Loss: 1.2133610248565674\nEpoch 3 -Loss: 0.7260757684707642\nEpoch 4 -Loss: 0.45562615990638733\nEpoch 5 -Loss: 0.7709782719612122\nEpoch 6 -Loss: 0.31321078538894653\nEpoch 7 -Loss: 0.3534226417541504\nEpoch 8 -Loss: 0.3829773962497711\nEpoch 9 -Loss: 0.2581394612789154\nEpoch 10 -Loss: 0.1306271255016327\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"### Define funciton to generate text","metadata":{}},{"cell_type":"code","source":"def generate_text(prompt,model,tokenizer,max_length=100):\n    inputs = tokenizer.encode_plus(prompt,return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"]\n    attention_mask = inputs[\"attention_mask\"]\n    outputs = model.generate(input_ids,\n                             attention_mask=attention_mask,\n                             max_length=max_length)\n    return tokenizer.decode(outputs[0],skip_special_tokens=True)\n\nprompt = \"what is Embedding?\"\n\ntext_generated = generate_text(prompt,model,tokenizer,max_length=500)\nprint(f\"text_generated: {text_generated}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:07:48.559387Z","iopub.execute_input":"2026-01-02T12:07:48.559732Z","iopub.status.idle":"2026-01-02T12:07:48.636291Z","shell.execute_reply.started":"2026-01-02T12:07:48.559708Z","shell.execute_reply":"2026-01-02T12:07:48.635597Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"text_generated: what is Embedding?\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## Tokenization and Embeddings","metadata":{}},{"cell_type":"code","source":"# install the faiss-cpu library\n!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:07:48.637256Z","iopub.execute_input":"2026-01-02T12:07:48.637664Z","iopub.status.idle":"2026-01-02T12:07:54.060345Z","shell.execute_reply.started":"2026-01-02T12:07:48.637631Z","shell.execute_reply":"2026-01-02T12:07:54.059580Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\nDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.13.2\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import faiss\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer,AutoModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:07:54.061726Z","iopub.execute_input":"2026-01-02T12:07:54.062117Z","iopub.status.idle":"2026-01-02T12:07:54.108846Z","shell.execute_reply.started":"2026-01-02T12:07:54.062088Z","shell.execute_reply":"2026-01-02T12:07:54.108252Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Initialize the tokenizer and model for generating embeddings\nmodel_id = \"sentence-transformers/paraphrase-MiniLM-L6-V2\"\nembed_tokenizer = AutoTokenizer.from_pretrained(model_id)\nembed_model = AutoModel.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:07:54.109810Z","iopub.execute_input":"2026-01-02T12:07:54.110044Z","iopub.status.idle":"2026-01-02T12:08:00.562190Z","shell.execute_reply.started":"2026-01-02T12:07:54.110023Z","shell.execute_reply":"2026-01-02T12:08:00.561637Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a36db8552224668a66d1d90af6e3b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e93112d6d6e4452a307e95a82faf697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3af8ffa36c2f4d3088acd98696e92ec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd47efd773464ecdac74d360338f1d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6581d2c1d5347389d0dc05c7fedc510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201c3ab1a70740d3b8e235b26c3ef135"}},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"documents = [\n\n# ===================== EDUCATION (20) =====================\n\n\"Ethiopia’s rapid university expansion after 2010 produced dozens of public institutions, but many campuses faced shortages of qualified faculty, laboratory equipment, and digital libraries, leading to uneven educational quality between flagship universities and newer regional institutions.\",\n\n\"The introduction of modular curricula in Ethiopian universities aimed to improve practical skills, yet implementation varied widely due to limited industry partnerships and insufficient internship opportunities in smaller regional economies.\",\n\n\"Secondary education reforms emphasized national exam standardization, but disparities persisted as rural schools struggled with teacher turnover, language-of-instruction transitions, and limited access to preparatory materials.\",\n\n\"Ethiopia’s push to expand STEM education increased engineering enrollments, while insufficient computing infrastructure and outdated syllabi slowed alignment with modern software and AI industry requirements.\",\n\n\"The growth of private universities widened access to higher education, but raised concerns regarding accreditation consistency, faculty qualifications, and graduate employability in Ethiopia’s constrained labor market.\",\n\n\"Language policy in Ethiopian education required students to transition from regional languages to English instruction, creating comprehension gaps that disproportionately affected rural learners during secondary and tertiary education.\",\n\n\"Teacher training colleges expanded rapidly, yet continuous professional development remained limited, affecting pedagogical quality in overcrowded classrooms across fast-growing urban and peri-urban areas.\",\n\n\"The COVID-19 school closures accelerated digital learning experiments, revealing significant inequalities in device ownership, electricity access, and household learning environments across Ethiopian regions.\",\n\n\"Technical and vocational education reforms aimed to address youth unemployment, but societal preference for university degrees reduced enrollment in TVET programs despite labor demand.\",\n\n\"University research output increased modestly, though limited funding and heavy teaching loads constrained faculty engagement in internationally competitive research activities.\",\n\n\"Ethiopia’s school feeding programs improved attendance in food-insecure regions, but funding sustainability and supply chain reliability remained ongoing operational challenges.\",\n\n\"Postgraduate education expanded in Ethiopian universities, yet doctoral supervision capacity lagged behind enrollment growth, affecting completion timelines and research quality.\",\n\n\"Curriculum decentralization allowed regions to adapt content to local contexts, though uneven capacity resulted in inconsistent learning outcomes nationwide.\",\n\n\"Digital student information systems were introduced in some universities, but interoperability challenges limited nationwide academic data integration.\",\n\n\"Gender parity initiatives improved female enrollment, yet retention gaps persisted due to early marriage, household labor expectations, and safety concerns.\",\n\n\"National education roadmaps emphasized competency-based learning, though assessment practices often remained exam-centered due to institutional inertia.\",\n\n\"Ethiopia’s boarding school models aimed to serve pastoralist communities, balancing mobility challenges with formal education continuity.\",\n\n\"The expansion of community schools increased rural access, but infrastructure quality and teacher allocation remained uneven.\",\n\n\"Graduate unemployment influenced student migration toward perceived marketable fields, sometimes oversaturating specific disciplines.\",\n\n\"Education financing reforms debated cost-sharing models amid rising enrollment pressures and limited public budgets.\",\n\n\n# ===================== RELIGION / ORTHODOX (20) =====================\n\n\"The Ethiopian Orthodox Tewahedo Church remains deeply intertwined with national identity, yet internal administrative disputes increasingly intersected with ethnic and regional political dynamics.\",\n\n\"Orthodox church education systems preserved Ge’ez literacy traditions, though declining enrollment among youth raised concerns about intergenerational knowledge transmission.\",\n\n\"Recent disagreements over ecclesiastical jurisdiction reflected broader federal-regional tensions rather than purely theological differences.\",\n\n\"The church’s vast land holdings influenced urban development negotiations, especially in expanding cities like Addis Ababa and Bahir Dar.\",\n\n\"Religious festivals continued to structure communal calendars, even as urbanization altered participation patterns and ritual practices.\",\n\n\"Monasteries in remote regions played roles in environmental conservation through traditional land stewardship practices.\",\n\n\"Interfaith relations evolved as urban neighborhoods hosted Orthodox, Muslim, and Protestant communities in close proximity.\",\n\n\"Digital media enabled clergy and lay scholars to disseminate teachings, altering traditional authority channels within the church.\",\n\n\"The training of priests faced challenges due to economic pressures that diverted youth toward income-generating activities.\",\n\n\"Disputes over language use in liturgy mirrored broader debates about cultural representation and inclusion.\",\n\n\"Orthodox charitable organizations expanded social services during humanitarian crises, supplementing limited state capacity.\",\n\n\"Church music traditions adapted to modern recording technologies while preserving liturgical structures.\",\n\n\"The role of the Orthodox Church in mediation efforts varied across regional conflicts.\",\n\n\"Restoration projects of ancient churches relied increasingly on diaspora funding.\",\n\n\"Urban parish administration struggled with rapid population growth and resource constraints.\",\n\n\"The church’s calendar influenced agricultural labor cycles in rural communities.\",\n\n\"Heritage preservation debates emerged around modernization near historic religious sites.\",\n\n\"Religious education curricula balanced doctrinal instruction with contemporary social issues.\",\n\n\"The visibility of clergy in public discourse evolved with increased media exposure.\",\n\n\"Monastic tourism raised sustainability and preservation concerns.\",\n\n\n# ===================== TECHNOLOGY (20) =====================\n\n\"Ethiopia’s telecom liberalization introduced competition, reshaping data pricing, network expansion priorities, and mobile financial service adoption beyond major urban centers.\",\n\n\"Local software developers faced constraints from limited access to international payment systems, affecting participation in global digital marketplaces.\",\n\n\"Fintech growth expanded mobile payments, though interoperability challenges persisted between platforms.\",\n\n\"Startup hubs in Addis Ababa supported innovation but struggled with funding continuity.\",\n\n\"Digital ID rollout aimed to unify service access while raising privacy and infrastructure concerns.\",\n\n\"Ethiopia’s data center investments targeted government digitization needs.\",\n\n\"Internet shutdowns disrupted digital businesses and remote education efforts.\",\n\n\"Agri-tech pilots used satellite data for yield estimation.\",\n\n\"E-commerce adoption remained constrained by logistics and addressing systems.\",\n\n\"Open-source communities grew through university-linked tech clubs.\",\n\n\"Cloud adoption was limited by bandwidth costs.\",\n\n\"Ride-hailing apps navigated regulatory uncertainty.\",\n\n\"AI research groups emerged within universities despite compute limitations.\",\n\n\"Digital health platforms supported appointment scheduling pilots.\",\n\n\"Payment APIs expanded merchant digitalization.\",\n\n\"Drone technology was tested for land surveying.\",\n\n\"Tech policy debates focused on data localization.\",\n\n\"Digital literacy programs targeted youth employment.\",\n\n\"Smart meter projects aimed to reduce utility losses.\",\n\n\"Local language NLP research faced dataset scarcity.\",\n\n\n# ===================== AGRICULTURE (20) =====================\n\n\"Ethiopia’s wheat self-sufficiency drive expanded irrigated farming in lowland areas.\",\n\n\"Smallholder farmers adopted improved seed varieties unevenly.\",\n\n\"Extension services increasingly used mobile messaging.\",\n\n\"Coffee traceability reforms enabled specialty exports.\",\n\n\"Climate variability affected planting calendars.\",\n\n\"Pastoralist mobility conflicted with fixed land use policies.\",\n\n\"Post-harvest losses remained a major challenge.\",\n\n\"Irrigation schemes altered traditional water-sharing norms.\",\n\n\"Fertilizer distribution reforms affected timing and access.\",\n\n\"Livestock exports depended on disease control systems.\",\n\n\"Agro-processing parks aimed to increase value addition.\",\n\n\"Soil degradation influenced long-term productivity.\",\n\n\"Rainfall forecasting tools supported adaptive planning.\",\n\n\"Market access varied due to road infrastructure.\",\n\n\"Urban demand shaped peri-urban farming.\",\n\n\"Seed certification improved quality assurance.\",\n\n\"Cooperative governance affected farmer bargaining power.\",\n\n\"Mechanization adoption was limited by cost.\",\n\n\"Crop insurance pilots addressed climate risk.\",\n\n\"Export crop diversification strategies expanded.\",\n\n\n# ===================== POLITICS (20) =====================\n\n\"Ethiopia’s federal system faced governance challenges amid shifting regional power dynamics.\",\n\n\"Electoral processes were influenced by security conditions.\",\n\n\"Decentralization policies complicated service delivery coordination.\",\n\n\"Political party fragmentation affected coalition stability.\",\n\n\"Administrative boundary disputes impacted local governance.\",\n\n\"Security sector reforms intersected with regional authority.\",\n\n\"Media liberalization expanded public discourse.\",\n\n\"Emergency regulations affected civil liberties debates.\",\n\n\"Peace negotiations shaped post-conflict transitions.\",\n\n\"Federal–regional fiscal relations influenced budget allocation.\",\n\n\"Identity politics shaped voter mobilization strategies.\",\n\n\"Judicial reform aimed to strengthen independence.\",\n\n\"Public sector reform targeted efficiency improvements.\",\n\n\"Foreign policy balanced regional diplomacy priorities.\",\n\n\"Legislative capacity faced resource constraints.\",\n\n\"Civil society space evolved under new regulations.\",\n\n\"Conflict resolution mechanisms varied by region.\",\n\n\"Urban governance reforms addressed service delivery.\",\n\n\"Policy continuity challenges followed leadership transitions.\",\n\n\"Political dialogue platforms aimed to reduce polarization.\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:08:00.563040Z","iopub.execute_input":"2026-01-02T12:08:00.563318Z","iopub.status.idle":"2026-01-02T12:08:00.573506Z","shell.execute_reply.started":"2026-01-02T12:08:00.563281Z","shell.execute_reply":"2026-01-02T12:08:00.572928Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def embed_text(text,tokenizer,model):\n    inputs = tokenizer(text,\n                       return_tensors=\"pt\",\n                       padding=True,\n                       truncation=True\n                       \n                      )\n    with torch.no_grad(): # tell pytorch to perform inference and don't build computation graph for backpass and gradient\n        embeddings = model(**inputs).last_hidden_state # last context riched tokens\n        # print(inputs)\n        # print(embeddings.shape)\n        embeddings = embeddings.mean(dim=1) # pooling token embeddings into single sentence embedding for the seek of retrieval system\n        # print(embeddings.shape)\n    return embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:59:03.693039Z","iopub.execute_input":"2026-01-02T12:59:03.693633Z","iopub.status.idle":"2026-01-02T12:59:03.697979Z","shell.execute_reply.started":"2026-01-02T12:59:03.693604Z","shell.execute_reply":"2026-01-02T12:59:03.697244Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"X = embed_text(\"is he student no matter how long you feed into the model it squeeze to 384 dim vector\",embed_tokenizer,embed_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:59:05.495967Z","iopub.execute_input":"2026-01-02T12:59:05.496653Z","iopub.status.idle":"2026-01-02T12:59:05.523642Z","shell.execute_reply.started":"2026-01-02T12:59:05.496624Z","shell.execute_reply":"2026-01-02T12:59:05.522968Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"embed_model,embed_tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:59:08.905866Z","iopub.execute_input":"2026-01-02T12:59:08.906414Z","iopub.status.idle":"2026-01-02T12:59:08.911721Z","shell.execute_reply.started":"2026-01-02T12:59:08.906384Z","shell.execute_reply":"2026-01-02T12:59:08.911030Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"(BertModel(\n   (embeddings): BertEmbeddings(\n     (word_embeddings): Embedding(30522, 384, padding_idx=0)\n     (position_embeddings): Embedding(512, 384)\n     (token_type_embeddings): Embedding(2, 384)\n     (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n     (dropout): Dropout(p=0.1, inplace=False)\n   )\n   (encoder): BertEncoder(\n     (layer): ModuleList(\n       (0-5): 6 x BertLayer(\n         (attention): BertAttention(\n           (self): BertSdpaSelfAttention(\n             (query): Linear(in_features=384, out_features=384, bias=True)\n             (key): Linear(in_features=384, out_features=384, bias=True)\n             (value): Linear(in_features=384, out_features=384, bias=True)\n             (dropout): Dropout(p=0.1, inplace=False)\n           )\n           (output): BertSelfOutput(\n             (dense): Linear(in_features=384, out_features=384, bias=True)\n             (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n             (dropout): Dropout(p=0.1, inplace=False)\n           )\n         )\n         (intermediate): BertIntermediate(\n           (dense): Linear(in_features=384, out_features=1536, bias=True)\n           (intermediate_act_fn): GELUActivation()\n         )\n         (output): BertOutput(\n           (dense): Linear(in_features=1536, out_features=384, bias=True)\n           (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n           (dropout): Dropout(p=0.1, inplace=False)\n         )\n       )\n     )\n   )\n   (pooler): BertPooler(\n     (dense): Linear(in_features=384, out_features=384, bias=True)\n     (activation): Tanh()\n   )\n ),\n BertTokenizerFast(name_or_path='sentence-transformers/paraphrase-MiniLM-L6-V2', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n }\n ))"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"# Initialize a list to store the bembeddings\ndocument_embeddings = []\n\nfor doc in documents:\n    doc_embeddings = embed_text(doc,embed_tokenizer,embed_model)\n    document_embeddings.append(doc_embeddings)\n\n\ndocument_embeddings[1].shape\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:59:15.518644Z","iopub.execute_input":"2026-01-02T12:59:15.519333Z","iopub.status.idle":"2026-01-02T12:59:16.842105Z","shell.execute_reply.started":"2026-01-02T12:59:15.519303Z","shell.execute_reply":"2026-01-02T12:59:16.841276Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 384])"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":" document_embeddings = torch.cat(document_embeddings).cpu().numpy()\ndocument_embeddings.shape, document_embeddings[:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:59:31.180555Z","iopub.execute_input":"2026-01-02T12:59:31.181083Z","iopub.status.idle":"2026-01-02T12:59:31.189737Z","shell.execute_reply.started":"2026-01-02T12:59:31.181054Z","shell.execute_reply":"2026-01-02T12:59:31.189039Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"((100, 384),\n array([[ 2.30880473e-02, -1.61137551e-01, -9.10027847e-02,\n          5.19852489e-02,  1.82184979e-01, -3.95213604e-01,\n         -7.83974648e-01,  1.36128411e-01,  8.63956138e-02,\n          3.58952075e-01,  9.72939562e-03,  2.33186856e-01,\n          4.01146524e-02,  1.65327922e-01, -4.39540818e-02,\n          5.85592687e-02, -3.67548198e-01, -3.28183115e-01,\n         -8.10759813e-02, -2.29089975e-01, -3.55545819e-01,\n         -3.25489372e-01, -1.91534236e-01, -2.62745433e-02,\n          2.69102871e-01,  1.42443748e-02, -1.06474422e-01,\n         -4.77159202e-01,  1.95637405e-01, -3.46150219e-01,\n          1.04308277e-01,  9.62997749e-02,  3.46982658e-01,\n          2.00115263e-01,  3.26267540e-01,  3.76052469e-01,\n          1.30603597e-01, -3.01188529e-01, -7.76710063e-02,\n          1.83142051e-02,  1.98836282e-01, -1.43699870e-01,\n         -1.14075430e-01, -1.63896292e-01,  2.06622362e-01,\n         -2.16120958e-01,  1.85457379e-01, -4.88813967e-02,\n         -2.96157867e-01, -9.99297276e-02,  1.15413465e-01,\n          1.64609313e-01, -8.46728981e-02, -3.05855591e-02,\n         -4.22802657e-01, -8.56973007e-02,  2.21406549e-01,\n          2.68590618e-02, -1.60758629e-01,  4.27499376e-02,\n         -3.51073414e-01,  1.31372467e-01, -1.12620510e-01,\n          1.65307686e-01,  9.21640173e-02, -3.86314392e-02,\n          3.66248250e-01,  1.87484905e-01, -8.85322131e-03,\n          1.76151410e-01, -1.52974442e-01, -1.91298217e-01,\n         -1.54966012e-01,  2.89871752e-01,  3.32765847e-01,\n          6.67425394e-02, -2.85994262e-02,  5.08759823e-03,\n          3.26483697e-01,  1.94046333e-01,  1.39012799e-01,\n         -9.01200399e-02,  2.43815314e-03, -2.86263019e-01,\n          1.67501613e-01, -1.74583644e-01, -1.51319847e-01,\n         -2.50166804e-01, -4.88305613e-02, -4.91636574e-01,\n          2.80424505e-01, -2.50639282e-02,  2.45644838e-01,\n          5.97643137e-01,  2.56164074e-01,  1.01105638e-01,\n         -8.61750618e-02, -3.33330810e-01,  3.62263620e-01,\n          7.01165125e-02, -2.98162967e-01, -2.86983754e-02,\n          4.66660261e-01, -1.46779390e-02, -5.45348004e-02,\n         -1.00926720e-02, -8.66501257e-02,  5.79420254e-02,\n          1.37176201e-01,  3.26948911e-02, -1.77979663e-01,\n         -2.11905316e-01, -5.69573827e-02, -1.14775263e-02,\n          2.28600696e-01, -4.42591459e-02, -9.49949399e-03,\n          1.02481134e-01, -5.22545397e-01,  4.15738553e-01,\n         -5.43025076e-01, -1.13901459e-01, -2.62114201e-02,\n         -5.55449843e-01, -2.07819939e-01,  3.16769540e-01,\n         -3.69079560e-01,  2.07384359e-02,  2.74772327e-02,\n         -2.39148825e-01, -2.16471687e-01, -2.10879594e-02,\n         -3.41146141e-01, -9.39563140e-02,  1.72087908e-01,\n          7.37972334e-02,  1.87678844e-01, -2.40434110e-01,\n         -4.91341427e-02,  2.84584105e-01,  7.08238408e-02,\n         -3.81280063e-03,  4.26335007e-01,  7.62941092e-02,\n          1.03372587e-02,  3.98742944e-01,  3.00986618e-01,\n          6.38043463e-01,  9.14123878e-02, -1.86072052e-01,\n          3.47017378e-01,  7.20667047e-03, -5.05137220e-02,\n          8.01959038e-02, -2.30457440e-01, -1.11551076e-01,\n          4.42084283e-01,  9.95233953e-02,  2.76319608e-02,\n         -1.20454237e-01, -1.53922975e-01, -1.90966845e-01,\n         -3.03703994e-01,  6.56445802e-04,  1.80183709e-01,\n          9.38501582e-02, -6.31460696e-02, -3.02721858e-01,\n         -4.57101613e-01,  5.58568537e-02,  1.66168869e-01,\n         -3.48375179e-02,  4.95061994e-01,  3.36498141e-01,\n          4.74194586e-01, -4.18242633e-01,  9.38422382e-02,\n         -1.04791194e-01, -2.24439919e-01,  7.89804682e-02,\n         -7.52738342e-02,  2.23027885e-01,  2.68915445e-01,\n         -2.60933429e-01,  4.15679365e-02,  1.97856992e-01,\n          3.79062831e-01, -1.12771757e-01,  3.32522541e-01,\n          1.72540128e-01, -4.25007343e-01,  1.13498315e-01,\n          4.71607983e-01, -2.83777207e-01,  2.46113017e-02,\n          1.58742040e-01,  4.70574260e-01, -4.56404209e-01,\n          1.50009647e-01, -3.10525503e-02, -2.74243355e-01,\n         -1.63826466e-01, -2.34002516e-01,  1.80959612e-01,\n         -1.54744640e-01, -7.17260037e-03, -2.52853185e-01,\n          3.80938351e-01,  8.45363662e-02, -5.23442738e-02,\n          4.67613004e-02, -2.08169371e-01, -2.66042147e-02,\n          8.84120017e-02,  1.07867263e-01,  1.09951738e-02,\n          3.61527413e-01,  6.17659371e-03,  9.20604691e-02,\n          1.05754599e-01,  1.21879444e-01,  3.10650587e-01,\n          1.79077566e-01, -1.37047544e-01,  4.41998035e-01,\n         -6.77275732e-02, -4.55968827e-01,  3.44424218e-01,\n         -3.75786573e-02,  8.98690000e-02, -4.20028456e-02,\n          4.75355446e-01, -3.86208087e-01, -3.08883429e-01,\n          4.31071930e-02,  2.58263666e-02,  2.01830924e-01,\n         -7.00006261e-02, -7.41194487e-01,  9.17200744e-02,\n          2.03205049e-01,  3.27240914e-01, -8.16132352e-02,\n          7.53665939e-02,  1.19062267e-01,  3.31586674e-02,\n          8.67790822e-03, -3.21402624e-02,  1.23768210e-01,\n         -1.01744704e-01, -5.55530429e-01, -5.47655404e-01,\n         -5.26616834e-02,  1.33532553e-03,  2.19616830e-01,\n          2.51663893e-01, -1.32641330e-01, -1.49995714e-01,\n          2.21176937e-01,  5.31992763e-02,  9.18409005e-02,\n         -1.78864390e-01, -2.12984800e-01,  2.62689203e-01,\n          2.35165298e-01,  5.01912013e-02,  9.40945968e-02,\n         -2.64085650e-01,  2.98416942e-01,  4.63733286e-01,\n         -2.93267131e-01, -1.14396542e-01,  1.70942992e-01,\n         -2.13444442e-01, -3.52394804e-02,  2.31107473e-01,\n          2.60381520e-01, -1.80864677e-01,  3.98503572e-01,\n         -4.21807647e-01,  7.46342391e-02,  4.22349632e-01,\n         -5.76952100e-01,  1.19629815e-01, -8.83640498e-02,\n         -4.95746173e-02, -2.39304245e-01, -6.28835857e-02,\n         -3.30037475e-01,  7.98402634e-03,  1.11939058e-01,\n          1.87321454e-01, -6.69624731e-02,  3.33940499e-02,\n          4.00720775e-01, -2.38088071e-01, -4.47388180e-02,\n         -1.55445943e-02, -2.56425738e-01,  2.96720028e-01,\n         -6.73266202e-02,  3.23844939e-01,  5.82353808e-02,\n          1.31551251e-01, -3.75930443e-02, -4.66258302e-02,\n          1.15997948e-01, -1.15657359e-01,  2.05278397e-03,\n          2.02013403e-01,  4.23347175e-01, -5.51771820e-01,\n         -1.19850878e-02,  5.44877052e-02, -1.95232242e-01,\n         -1.24114566e-02, -1.05489604e-01,  1.00571357e-01,\n          5.50106883e-01, -1.16639346e-01,  2.44811215e-02,\n          7.42619112e-02, -1.72886118e-01,  2.19708353e-01,\n         -4.04260382e-02,  1.42994925e-01, -3.11479717e-01,\n          7.65964389e-02, -4.26679254e-02,  3.19626629e-01,\n         -3.94447237e-01, -1.41249627e-01, -5.48271239e-01,\n          3.57980311e-01,  2.51432747e-01,  2.51213551e-01,\n         -3.70718092e-02,  9.68411565e-02,  6.97782859e-02,\n         -4.93176794e-03,  1.32398903e-01,  2.64452435e-02,\n          1.99775547e-01,  7.83715621e-02,  8.77256095e-02,\n         -5.82280271e-02,  3.46033335e-01,  6.94692433e-02,\n         -1.73729643e-01, -3.72785687e-01, -3.12755644e-01,\n         -2.05478415e-01, -3.29622447e-01, -1.87151253e-01,\n          4.70703423e-01,  1.78020418e-01, -3.47964048e-01,\n         -9.30244103e-02, -2.10189283e-01,  1.05705090e-01,\n          4.23144503e-03, -4.40031677e-01,  2.25404605e-01,\n         -1.32058680e-01,  5.46277940e-01,  5.58470339e-02,\n         -5.01928747e-01,  3.77656460e-01,  1.72352731e-01,\n         -1.22954540e-01, -7.75284767e-02, -1.05241016e-01,\n         -2.31260389e-01, -4.46226954e-01,  2.22780362e-01,\n         -3.86682123e-01, -2.74501473e-01,  1.20336786e-01,\n         -4.27343905e-01, -1.78506933e-02,  1.34562686e-01,\n         -1.14264943e-01,  6.58334315e-01, -3.94704193e-02]], dtype=float32))"},"metadata":{}}],"execution_count":97},{"cell_type":"markdown","source":"### Build the Retrieval System","metadata":{}},{"cell_type":"code","source":"document_embeddings.shape,document_embeddings[1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:08:00.123464Z","iopub.execute_input":"2026-01-02T13:08:00.124319Z","iopub.status.idle":"2026-01-02T13:08:00.130303Z","shell.execute_reply.started":"2026-01-02T13:08:00.124275Z","shell.execute_reply":"2026-01-02T13:08:00.129395Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"((100, 384), (384,))"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":" index = faiss.IndexFlatL2(document_embeddings.shape[1])\nindex.add(document_embeddings)\nprint(index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:08:02.779822Z","iopub.execute_input":"2026-01-02T13:08:02.780523Z","iopub.status.idle":"2026-01-02T13:08:02.785189Z","shell.execute_reply.started":"2026-01-02T13:08:02.780491Z","shell.execute_reply":"2026-01-02T13:08:02.784300Z"}},"outputs":[{"name":"stdout","text":"<faiss.swigfaiss_avx512.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7f5a84742b50> >\n","output_type":"stream"}],"execution_count":110},{"cell_type":"code","source":"faiss.downcast_index(index)\nindex.d, index.ntotal, index.is_trained,index.metric_type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:00:43.741762Z","iopub.execute_input":"2026-01-02T13:00:43.742453Z","iopub.status.idle":"2026-01-02T13:00:43.748341Z","shell.execute_reply.started":"2026-01-02T13:00:43.742415Z","shell.execute_reply":"2026-01-02T13:00:43.747203Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"(384, 100, True, 1)"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"# Retrieval -> Build a function to retrieve information\ndef retrieve(query,tokenizer,model,index,documents,top_k=3):\n    query_embeddings = embed_text(query,tokenizer,model)\n    distances, indices = index.search(query_embeddings,top_k)\n    return [documents[i] for i in indices[0]],distances[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:03:35.563948Z","iopub.execute_input":"2026-01-02T13:03:35.564419Z","iopub.status.idle":"2026-01-02T13:03:35.569069Z","shell.execute_reply.started":"2026-01-02T13:03:35.564387Z","shell.execute_reply":"2026-01-02T13:03:35.568195Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"# Test the retrieval function\nquery = \"ethiopain technology development journey\"\nretrieved_docs,distances = retrieve(query,embed_tokenizer,embed_model,index,documents)\nfor d in retrieved_docs:\n    print(d)\n    print(\"\\n\"*5)\nprint(distances)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:03:39.137435Z","iopub.execute_input":"2026-01-02T13:03:39.138018Z","iopub.status.idle":"2026-01-02T13:03:39.163143Z","shell.execute_reply.started":"2026-01-02T13:03:39.137988Z","shell.execute_reply":"2026-01-02T13:03:39.162593Z"}},"outputs":[{"name":"stdout","text":"Ethiopia’s push to expand STEM education increased engineering enrollments, while insufficient computing infrastructure and outdated syllabi slowed alignment with modern software and AI industry requirements.\n\n\n\n\n\n\nAI research groups emerged within universities despite compute limitations.\n\n\n\n\n\n\nThe COVID-19 school closures accelerated digital learning experiments, revealing significant inequalities in device ownership, electricity access, and household learning environments across Ethiopian regions.\n\n\n\n\n\n\n[53.034523 53.730743 54.004635]\n","output_type":"stream"}],"execution_count":106},{"cell_type":"markdown","source":"### Integrating The Generative System","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM,AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:08:02.042099Z","iopub.execute_input":"2026-01-02T12:08:02.042414Z","iopub.status.idle":"2026-01-02T12:08:02.046162Z","shell.execute_reply.started":"2026-01-02T12:08:02.042390Z","shell.execute_reply":"2026-01-02T12:08:02.045417Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Initialize the generative tokenizer and model\ngen_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ngen_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\ngen_tokenizer.pad_token = gen_tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:08:02.046997Z","iopub.execute_input":"2026-01-02T12:08:02.047282Z","iopub.status.idle":"2026-01-02T12:08:03.461256Z","shell.execute_reply.started":"2026-01-02T12:08:02.047258Z","shell.execute_reply":"2026-01-02T12:08:03.460440Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"context = \" \".join(retrieved_docs)\ncontext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:05:20.424080Z","iopub.execute_input":"2026-01-02T13:05:20.425004Z","iopub.status.idle":"2026-01-02T13:05:20.430280Z","shell.execute_reply.started":"2026-01-02T13:05:20.424972Z","shell.execute_reply":"2026-01-02T13:05:20.429423Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"'Ethiopia’s push to expand STEM education increased engineering enrollments, while insufficient computing infrastructure and outdated syllabi slowed alignment with modern software and AI industry requirements. AI research groups emerged within universities despite compute limitations. The COVID-19 school closures accelerated digital learning experiments, revealing significant inequalities in device ownership, electricity access, and household learning environments across Ethiopian regions.'"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"# Function to generate context riched text\ndef generate_text(context,query,model,tokenizer):\n    input_text =   f\"Context: {context} \\n Question:{query} \\n Answer:\"\n    inputs = tokenizer(input_text,\n                       return_tensors=\"pt\",\n                       padding=True,\n                      truncation=True)\n    inputs_ids = inputs[\"input_ids\"]\n    (inputs_ids != tokenizer.pad_token_id)\n    attention_masks = inputs[\"attention_mask\"]\n    outputs = model.generate(inputs_ids,\n                                attention_mask=attention_masks,\n                                max_new_tokens=150,\n                                 do_sample=True,\n                                 top_p=80,\n                                 top_k=50,\n                                 repetition_penalty=1.2,\n                                 temperature=0.1,\n                                pad_token_id=gen_tokenizer.eos_token_id)\n    outputs.shape,outputs\n    \n    \n    return tokenizer.decode(outputs[0],skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:10:09.300646Z","iopub.execute_input":"2026-01-02T13:10:09.301494Z","iopub.status.idle":"2026-01-02T13:10:09.307785Z","shell.execute_reply.started":"2026-01-02T13:10:09.301463Z","shell.execute_reply":"2026-01-02T13:10:09.307015Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"generated_answer = generate_text(context,query,gen_model,gen_tokenizer)\nprint(f\"generated anser:\\n {generated_answer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:10:13.375264Z","iopub.execute_input":"2026-01-02T13:10:13.376153Z","iopub.status.idle":"2026-01-02T13:10:19.667169Z","shell.execute_reply.started":"2026-01-02T13:10:13.376117Z","shell.execute_reply":"2026-01-02T13:10:19.666288Z"}},"outputs":[{"name":"stdout","text":"generated anser:\n Context: Ethiopia’s push to expand STEM education increased engineering enrollments, while insufficient computing infrastructure and outdated syllabi slowed alignment with modern software and AI industry requirements. AI research groups emerged within universities despite compute limitations. The COVID-19 school closures accelerated digital learning experiments, revealing significant inequalities in device ownership, electricity access, and household learning environments across Ethiopian regions. \n Question:ethiopain technology development journey \n Answer:Ethipanese government has been working on a new generation of high quality IT solutions for the past decade that will improve productivity by increasing efficiency through innovation (elevating performance). In this context we are concerned about how these technologies may impact economic growth as well as social mobility among Ethiopians who live outside their country. We believe it is important to understand what drives technological progress throughout Africa's history; whether they can be sustained or not—and why so many have chosen them over other options such at home versus abroad . This article examines some key issues related both to technical advancement opportunities from developing countries' emerging economies and challenges facing those nations today when compared against current trends toward greater use of advanced computer science skills globally , including robotics/machine intelligence capabilities worldwide\n","output_type":"stream"}],"execution_count":113},{"cell_type":"markdown","source":"### RAG System","metadata":{}},{"cell_type":"code","source":"# Define the RAG function that integrates retrieval and generation\ndef rag(query,retrieval_tokenizer,retrieval_model,retrieval_index,gen_model,gen_tokenizer,documents,top_k=3):\n    retrieved_docs, distances = retrieve(query,\n                                      retrieval_tokenizer,\n                                      retrieval_model,\n                                      retrieval_index,\n                                      documents,\n                                         top_k)\n    context = \" \".join(retrieved_docs)\n    generated_answer = generate_text(context,query,gen_model,gen_tokenizer)\n    return generated_answer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:12:55.446251Z","iopub.execute_input":"2026-01-02T13:12:55.447176Z","iopub.status.idle":"2026-01-02T13:12:55.451541Z","shell.execute_reply.started":"2026-01-02T13:12:55.447145Z","shell.execute_reply":"2026-01-02T13:12:55.450793Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"# Test the rag system\nquery = \"Ethiopian university learning strategy\"\nanswer = rag(query,embed_tokenizer,embed_model,index,gen_model,gen_tokenizer,documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:13:06.119030Z","iopub.execute_input":"2026-01-02T13:13:06.119455Z","iopub.status.idle":"2026-01-02T13:13:14.339686Z","shell.execute_reply.started":"2026-01-02T13:13:06.119425Z","shell.execute_reply":"2026-01-02T13:13:14.338814Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":" print(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:13:14.340808Z","iopub.execute_input":"2026-01-02T13:13:14.341015Z","iopub.status.idle":"2026-01-02T13:13:14.348386Z","shell.execute_reply.started":"2026-01-02T13:13:14.340994Z","shell.execute_reply":"2026-01-02T13:13:14.346262Z"}},"outputs":[{"name":"stdout","text":"Context: Postgraduate education expanded in Ethiopian universities, yet doctoral supervision capacity lagged behind enrollment growth, affecting completion timelines and research quality. The introduction of modular curricula in Ethiopian universities aimed to improve practical skills, yet implementation varied widely due to limited industry partnerships and insufficient internship opportunities in smaller regional economies. Language policy in Ethiopian education required students to transition from regional languages to English instruction, creating comprehension gaps that disproportionately affected rural learners during secondary and tertiary education. \n Question:Ethiopian university learning strategy \n Answer: In Ethiopia's academic system, the primary goal is for undergraduate degree holders to gain a high level of proficiency with basic knowledge (e-learning) while also gaining experience as an educator or researcher who can provide critical feedback on their own work through informal peer review processes; however this approach has not been implemented effectively across all sectors within academia [1]. This study examined how educational institutions have responded by providing more formalized training programs designed to prepare graduates into professional roles at higher levels than those currently available under traditional teaching methods such both online courses offered via e-books/online platforms like Wikipedia[2], but which are often subject only one language per student rather then multiple dialects.[3] These systems were developed using data collected over time based upon national surveys\n","output_type":"stream"}],"execution_count":116},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGITHUB_OPENAI_API_KEY= user_secrets.get_secret(\"GITHUB_OPENAI_API_KEY\")\nGITHUB_OPENAI_URL= user_secrets.get_secret(\"GITHUB_OPENAI_URL\")\n# GITHUB_OPENAI_API_KEY,GITHUB_OPENAI_URL\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:22:43.681901Z","iopub.execute_input":"2026-01-02T13:22:43.682460Z","iopub.status.idle":"2026-01-02T13:22:44.135852Z","shell.execute_reply.started":"2026-01-02T13:22:43.682430Z","shell.execute_reply":"2026-01-02T13:22:44.135269Z"}},"outputs":[],"execution_count":119},{"cell_type":"markdown","source":"### Perform OCR and transform to images","metadata":{}},{"cell_type":"code","source":"# !pip install pdf2image\n# !apt-get install -y poppler-utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:40:52.897439Z","iopub.execute_input":"2026-01-02T20:40:52.897756Z","iopub.status.idle":"2026-01-02T20:40:52.901729Z","shell.execute_reply.started":"2026-01-02T20:40:52.897724Z","shell.execute_reply":"2026-01-02T20:40:52.901052Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":" from pdf2image import convert_from_path\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:40:54.857833Z","iopub.execute_input":"2026-01-02T20:40:54.858470Z","iopub.status.idle":"2026-01-02T20:40:54.861886Z","shell.execute_reply.started":"2026-01-02T20:40:54.858442Z","shell.execute_reply":"2026-01-02T20:40:54.861145Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def pdf_to_images(pdf_path  ,output_folder):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n    images = convert_from_path(pdf_path)\n    images_path = []\n    for i, image in enumerate(images):\n        image_path = os.path.join(output_folder,f\"page{i+1}.jpg\")\n        image.save(image_path,\"JPEG\")\n        images_path.append(image_path)\n    return images_path\n         ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:40:57.106595Z","iopub.execute_input":"2026-01-02T20:40:57.107278Z","iopub.status.idle":"2026-01-02T20:40:57.111763Z","shell.execute_reply.started":"2026-01-02T20:40:57.107252Z","shell.execute_reply":"2026-01-02T20:40:57.110847Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/mother-book/things-mother-used-to-make.pdf\"\noutput_folder = \"images\"\n\nimage_paths = pdf_to_images(pdf_path,output_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:43:57.449708Z","iopub.execute_input":"2026-01-02T20:43:57.450396Z","iopub.status.idle":"2026-01-02T20:45:51.647153Z","shell.execute_reply.started":"2026-01-02T20:43:57.450366Z","shell.execute_reply":"2026-01-02T20:45:51.646331Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# !pip install openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T18:40:45.443222Z","iopub.status.idle":"2026-01-02T18:40:45.443452Z","shell.execute_reply.started":"2026-01-02T18:40:45.443340Z","shell.execute_reply":"2026-01-02T18:40:45.443354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from openai import OpenAI\nimport base64\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGITHUB_OPENAI_API_KEY= user_secrets.get_secret(\"GITHUB_OPENAI_API_KEY\")\nGITHUB_OPENAI_URL = user_secrets.get_secret(\"GITHUB_OPENAI_URL\")\nGITHUB_OPENAI_URL\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:51.648685Z","iopub.execute_input":"2026-01-02T20:45:51.648959Z","iopub.status.idle":"2026-01-02T20:45:51.786202Z","shell.execute_reply.started":"2026-01-02T20:45:51.648929Z","shell.execute_reply":"2026-01-02T20:45:51.785484Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'https://models.inference.ai.azure.com'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"client = OpenAI(\n    api_key=GITHUB_OPENAI_API_KEY,\n    base_url=GITHUB_OPENAI_URL\n    )\nmodel = \"gpt-4o\"\nimage_path = \"images/page23.jpg\"\nwith open(image_path,\"rb\") as image_file:\n    image_data = base64.b64encode(image_file.read()).decode('utf-8')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:51.787121Z","iopub.execute_input":"2026-01-02T20:45:51.787491Z","iopub.status.idle":"2026-01-02T20:45:52.120869Z","shell.execute_reply.started":"2026-01-02T20:45:51.787460Z","shell.execute_reply":"2026-01-02T20:45:52.120075Z"},"_kg_hide-input":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T19:36:49.000265Z","iopub.execute_input":"2026-01-02T19:36:49.000960Z","iopub.status.idle":"2026-01-02T19:36:49.004713Z","shell.execute_reply.started":"2026-01-02T19:36:49.000901Z","shell.execute_reply":"2026-01-02T19:36:49.003980Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"import random\ndef get_random_image():\n    random_page = random.randint(1,140)\n    random_image_path = os.path.join(os.getcwd(),\"images\",f\"page{random_page}.jpg\")\n    with open(random_image_path,\"rb\") as random_image:\n        image_data = base64.b64encode(random_image.read()).decode(\"utf-8\")\n    return image_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:52.122774Z","iopub.execute_input":"2026-01-02T20:45:52.123075Z","iopub.status.idle":"2026-01-02T20:45:52.128179Z","shell.execute_reply.started":"2026-01-02T20:45:52.123053Z","shell.execute_reply":"2026-01-02T20:45:52.127486Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"system_prompt = \"\"\"\nplease analyze the content of this image and extract any related recipe information\n\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:52.129110Z","iopub.execute_input":"2026-01-02T20:45:52.129498Z","iopub.status.idle":"2026-01-02T20:45:52.139834Z","shell.execute_reply.started":"2026-01-02T20:45:52.129447Z","shell.execute_reply":"2026-01-02T20:45:52.139116Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"random_image_data = get_random_image()\n# random_image_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:52.140789Z","iopub.execute_input":"2026-01-02T20:45:52.141048Z","iopub.status.idle":"2026-01-02T20:45:52.150776Z","shell.execute_reply.started":"2026-01-02T20:45:52.141021Z","shell.execute_reply":"2026-01-02T20:45:52.150098Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"random_image_data = get_random_image()\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[\n        {\n            \"role\":\"system\",\"content\":system_prompt\n        },\n        {\n            \"role\":\"user\",\"content\":[\n                \"this is the image from the recipe page.\",\n                {\n                    \"type\":\"image_url\",\n                    \"image_url\":{\"url\":f\"data:image/jpeg;base64,{random_image_data}\"},\n                    \"detail\":\"low\"\n                }\n            ]\n        }\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:52.151651Z","iopub.execute_input":"2026-01-02T20:45:52.151982Z","iopub.status.idle":"2026-01-02T20:45:58.474553Z","shell.execute_reply.started":"2026-01-02T20:45:52.151960Z","shell.execute_reply":"2026-01-02T20:45:58.473607Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"gpt_response = response.choices[0].message.content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:58.475697Z","iopub.execute_input":"2026-01-02T20:45:58.475983Z","iopub.status.idle":"2026-01-02T20:45:58.479606Z","shell.execute_reply.started":"2026-01-02T20:45:58.475953Z","shell.execute_reply":"2026-01-02T20:45:58.478833Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# !pip install ipython","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T19:10:06.565377Z","iopub.execute_input":"2026-01-02T19:10:06.566231Z","iopub.status.idle":"2026-01-02T19:10:06.569516Z","shell.execute_reply.started":"2026-01-02T19:10:06.566197Z","shell.execute_reply":"2026-01-02T19:10:06.568743Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"from IPython.display import Markdown,display\ndef markdown_display(response,markdown=Markdown,display=display):\n    markdown_content = response.choices[0].message.content\n    display(markdown(markdown_content))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:58.480679Z","iopub.execute_input":"2026-01-02T20:45:58.480881Z","iopub.status.idle":"2026-01-02T20:45:58.488462Z","shell.execute_reply.started":"2026-01-02T20:45:58.480861Z","shell.execute_reply":"2026-01-02T20:45:58.487639Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"markdown_display(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:58.490170Z","iopub.execute_input":"2026-01-02T20:45:58.490397Z","iopub.status.idle":"2026-01-02T20:45:58.502292Z","shell.execute_reply.started":"2026-01-02T20:45:58.490377Z","shell.execute_reply":"2026-01-02T20:45:58.501473Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"This image appears to show a page from a book that contains several short recipes, tips, and household advice. Here's the recipe and advice content from the image:\n\n### Never Throw Away Sour Milk\n- **Use for baking**: \n  - Sour milk is excellent for graham bread, gingerbread, brown bread, griddle cakes, and doughnuts. \n  - It can also be utilized in making biscuits.\n- **Create cottage cheese**:\n  - Set the milk on the back of the stove, in an agate dish. Let it sit until the whey separates from the curd.\n  - Strain through a cloth, squeezing the curd dry.\n  - Put into a little salt, a small piece of butter, and a little sage if desired.\n  - Press into balls and serve.\n\n### Mark New Rubbers\n- To mark new rubbers, take a sharp stick such as a wooden skewer from the butcher’s. Heat it red-hot and write the name on the inside of the rubber with it.\n\n### Economical Hints\n- **Use scraps of soap for hand-washing/washing clothes**: \n  - Place small pieces of soap in hot water and keep them in a cup or small bowl. Once dissolved, you’ll have a supply of liquid soap.\n- **Reuse paper bags**:\n  - Use the white papers from cracker boxes. They can be repurposed as handy items to clean irons and other surfaces.\n\nThese tips combine practical household advice with ideas for repurposing common household items."},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"system_prompt_2 = \"\"\"\nplease analyze the content of this image and extract any related recipe information into\nstructured components. specifically, extract the recipe title, list of ingredients, step by step instructions, cuisine type,\ndish type,any relevant tags or metadata.\noutput must be formatted in a way suited for embedding in a Retrieval Augemented \nGeneration system.\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:45:58.503391Z","iopub.execute_input":"2026-01-02T20:45:58.503716Z","iopub.status.idle":"2026-01-02T20:45:58.510459Z","shell.execute_reply.started":"2026-01-02T20:45:58.503684Z","shell.execute_reply":"2026-01-02T20:45:58.509701Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"response = client.chat.completions.create(\n    model=model,\n    messages=[\n        {\"role\":\"system\",\"content\":system_prompt_2},\n        {\"role\":\"user\",\"content\":[\n            \"this is the image from the recipe page\",\n            {\"type\":\"image_url\",\n             \"image_url\":{\"url\":f\"data:image/jpeg;base64,{get_random_image()}\",\n                          \"detail\":\"low\"}\n            }\n        ]}\n    ],\n    \n         temperature=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:48:56.360761Z","iopub.execute_input":"2026-01-02T20:48:56.361066Z","iopub.status.idle":"2026-01-02T20:49:05.029293Z","shell.execute_reply.started":"2026-01-02T20:48:56.361041Z","shell.execute_reply":"2026-01-02T20:49:05.028766Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"markdown_display(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T20:49:05.030530Z","iopub.execute_input":"2026-01-02T20:49:05.030877Z","iopub.status.idle":"2026-01-02T20:49:05.035629Z","shell.execute_reply.started":"2026-01-02T20:49:05.030843Z","shell.execute_reply":"2026-01-02T20:49:05.034900Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is the extracted recipe information from the image:\n\n---\n\n### Recipe 1: Currant Jelly\n**Ingredients:**\n- Currants (quantity not specified)\n- Water (enough to cover the currants)\n- Juice (1 pint of juice to 1 pint of sugar)\n- Sugar (1 pint per pint of juice)\n\n**Instructions:**\n1. Pick currants from the stems and wash clean.\n2. Put them into a kettle with a very little water and cook for ten minutes.\n3. Strain through a flannel bag.\n4. Use one pint of juice to one pint of sugar.\n5. Boil the juice and sugar five minutes, add sugar, and boil five minutes more.\n6. Pour into tumblers or jelly molds, and when cold, cover with paraffin.\n\n**Cuisine Type:** Traditional  \n**Dish Type:** Jelly  \n**Tags:** Preserves, Currant, Jelly, Traditional Recipe  \n\n---\n\n### Recipe 2: Spiced Currants\n**Ingredients:**\n- 5 pounds of currants\n- 4 pounds of sugar\n- 1 pint of vinegar\n- 4 teaspoons of cinnamon\n- 4 teaspoons of cloves\n\n**Instructions:**\n1. Boil slowly for two and a half hours.\n2. Tie the spices in a cloth before boiling.\n\n**Cuisine Type:** Traditional  \n**Dish Type:** Preserve  \n**Tags:** Spiced, Currant, Preserve, Traditional Recipe  \n\n---\n\n### Recipe 3: Cranberry Jelly\n**Ingredients:**\n- 1 quart of cranberries\n- 3½ cups of sugar\n\n**Instructions:**\n1. Put one quart of cranberries on the stove with cold water enough to cover.\n2. Boil until soft, then strain through a colander.\n3. To this four cups of juice, add three and a half cups of sugar.\n4. Boil twenty minutes and turn into a mold, which has been wet with cold water.\n\n**Cuisine Type:** Traditional  \n**Dish Type:** Jelly  \n**Tags:** Cranberry, Jelly, Traditional Recipe  \n\n--- \n\nThis structured information is ready for embedding in a Retrieval-Augmented Generation system."},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"from concurrent.futures import ThreadPoolExecutor\nextracted_recipes = []\nfor image_path in image_paths:\n    def process_image(image_path):\n        with open(image_path,'rb') as image_file:\n            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n\n    \n    response = client.chat.completions.create(\n    model=model,\n    messages=[\n        {\"role\":\"system\",\"content\":system_prompt_2},\n        {\"role\":\"user\",\"content\":[\n            \"this is the image from the recipe page\",\n            {\"type\":\"image_url\",\n             \"image_url\":{\"url\":f\"data:image/jpeg;base64,{get_random_image()}\",\n                          \"detail\":\"low\"}\n            }\n        ]}\n    ],\n    \n         temperature=0\n)\n    gpt_response = response.choices[0].message.content \n    extracted_recipes.append({\"image_path\":image_path,\"recipe_info\":gpt_response})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:02:19.221626Z","iopub.execute_input":"2026-01-02T21:02:19.222437Z","iopub.status.idle":"2026-01-02T21:02:21.572875Z","shell.execute_reply.started":"2026-01-02T21:02:19.222407Z","shell.execute_reply":"2026-01-02T21:02:21.571956Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1816293351.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     messages=[\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 79312 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 79312 seconds before retrying.'}}"],"ename":"RateLimitError","evalue":"Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 79312 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 79312 seconds before retrying.'}}","output_type":"error"}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}