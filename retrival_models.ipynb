{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"authorship_tag":"ABX9TyMbKGTK525va4gtoTXtzK31","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Probablistic retrival model, Fundamental of RAG","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:31:56.731885Z","iopub.execute_input":"2025-12-24T07:31:56.732262Z","iopub.status.idle":"2025-12-24T07:31:56.736991Z","shell.execute_reply.started":"2025-12-24T07:31:56.732230Z","shell.execute_reply":"2025-12-24T07:31:56.736097Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Initialize the tokenizer and the model\nmodel_id = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:31:56.751286Z","iopub.execute_input":"2025-12-24T07:31:56.751604Z","iopub.status.idle":"2025-12-24T07:31:57.405415Z","shell.execute_reply.started":"2025-12-24T07:31:56.751572Z","shell.execute_reply":"2025-12-24T07:31:57.404651Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(tokenizer.encode(\"<|endoftext|>\",return_tensors=\"pt\"))\nprint(tokenizer.decode(range(200)))\nprint(tokenizer.decode([20755]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:40:18.685798Z","iopub.execute_input":"2025-12-24T07:40:18.686128Z","iopub.status.idle":"2025-12-24T07:40:18.692402Z","shell.execute_reply.started":"2025-12-24T07:40:18.686098Z","shell.execute_reply":"2025-12-24T07:40:18.691615Z"}},"outputs":[{"name":"stdout","text":"tensor([[50256]])\n!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~����������������������������������������������������������������������������������������������\u0000\u0001\u0002\u0003\u0004\u0005\u0006\t\n\u000b\n impacted\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"print(tokenizer)\nprint(f\"model:{model}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:32:40.119687Z","iopub.execute_input":"2025-12-24T07:32:40.120265Z","iopub.status.idle":"2025-12-24T07:32:40.125268Z","shell.execute_reply.started":"2025-12-24T07:32:40.120231Z","shell.execute_reply":"2025-12-24T07:32:40.124571Z"}},"outputs":[{"name":"stdout","text":"GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}\n)\nmodel:GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# simplified text generation function\nprompt = \"Dear boss ...\"\n\ndef simple_text_generation(prompt,model,tokenizer,max_length=100):\n    input_ids =  tokenizer.encode(prompt,return_tensors=\"pt\") # pt = pytorch\n    # print(f\"prompt:{prompt}\\n input_ids: {input_ids}\")\n    outputs = model.generate(input_ids,max_length=100)\n    \n    # print(f\"generated result: {outputs}\")\n    \n    sentence = tokenizer.decode(outputs[0],skip_special_tokens=True)\n    # print(f\"outputs: {sentence}\")\n    return sentence\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:31:57.406883Z","iopub.execute_input":"2025-12-24T07:31:57.407198Z","iopub.status.idle":"2025-12-24T07:31:57.412035Z","shell.execute_reply.started":"2025-12-24T07:31:57.407167Z","shell.execute_reply":"2025-12-24T07:31:57.411391Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"prompt = \"Dear boss ...\"\ntext_generated = simple_text_generation(prompt,\n                                        model,\n                                        tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:31:57.413025Z","iopub.execute_input":"2025-12-24T07:31:57.413413Z","iopub.status.idle":"2025-12-24T07:32:00.943042Z","shell.execute_reply.started":"2025-12-24T07:31:57.413379Z","shell.execute_reply":"2025-12-24T07:32:00.942261Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(text_generated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:32:00.944796Z","iopub.execute_input":"2025-12-24T07:32:00.945125Z","iopub.status.idle":"2025-12-24T07:32:00.951225Z","shell.execute_reply.started":"2025-12-24T07:32:00.945085Z","shell.execute_reply":"2025-12-24T07:32:00.950482Z"}},"outputs":[{"name":"stdout","text":"Dear boss ... I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I'm not going to be able to do this anymore. I\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T07:32:12.905800Z","iopub.execute_input":"2025-12-24T07:32:12.906181Z","iopub.status.idle":"2025-12-24T07:32:12.910591Z","shell.execute_reply.started":"2025-12-24T07:32:12.906150Z","shell.execute_reply":"2025-12-24T07:32:12.909762Z"}},"outputs":[{"name":"stdout","text":"GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}\n)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}